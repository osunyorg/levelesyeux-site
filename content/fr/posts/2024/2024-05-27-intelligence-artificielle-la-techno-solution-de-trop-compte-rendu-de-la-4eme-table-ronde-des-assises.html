---
title: >-
  Intelligence Artificielle : la techno-solution de trop ? - Compte-rendu de la 4ème table ronde des Assises de l'attention 2024
subtitle: >-
  
bodyclass: >-
   
url: "/actualites/2024-05-27-intelligence-artificielle-la-techno-solution-de-trop-compte-rendu-de-la-4eme-table-ronde-des-assises/"
slug: "intelligence-artificielle-la-techno-solution-de-trop-compte-rendu-de-la-4eme-table-ronde-des-assises"
date: 2024-05-27T00:00:00+02:00
lastmod: 2024-09-30T11:22:12+02:00
meta:
  hugo:
    permalink: "/actualites/2024-05-27-intelligence-artificielle-la-techno-solution-de-trop-compte-rendu-de-la-4eme-table-ronde-des-assises/"
    path: "/posts/2024/2024-05-27-intelligence-artificielle-la-techno-solution-de-trop-compte-rendu-de-la-4eme-table-ronde-des-assises"
    file: "content/fr/posts/2024/2024-05-27-intelligence-artificielle-la-techno-solution-de-trop-compte-rendu-de-la-4eme-table-ronde-des-assises.html"
    slug: "intelligence-artificielle-la-techno-solution-de-trop-compte-rendu-de-la-4eme-table-ronde-des-assises"
  dates:
    created_at: 2024-05-27T15:10:27+02:00
    updated_at: 2024-09-30T11:22:12+02:00
    published_at: 2024-05-27T00:00:00+02:00
search:
  id: "48197cbe-9a20-400b-893c-2925dbce08af"
  url: "/actualites/2024-05-27-intelligence-artificielle-la-techno-solution-de-trop-compte-rendu-de-la-4eme-table-ronde-des-assises/"
  kind: "Communication::Website::Post::Localization"
  lang: "fr"
  title: >-
    Intelligence Artificielle : la techno-solution de trop ? - Compte-rendu de la 4ème table ronde des Assises de l'attention 2024
  summary: >-
    <p>En présence de Marius Bertolucci, Laurence Devillers et Diego Hidalgo. Modération par Anthony Laurent, prise de notes par Victor Fersing. </p>
  body: >-
    <p>  <br>Dérèglement climatique, migrations, gestion administrative, justice, santé… face aux multiples défis auxquels l’humanité fait face, la nouvelle solution des techno prophètes est bien l’intelligence artificielle. Les risques liés à la massification de cette technologie sont, pourtant, étourdissants. Quelles pistes de solutions crédibles sont envisagées, du côté de la société civile ou de l’Union européenne ? En présence de :-       Marius Bertolucci, Maître de conférence en sciences de gestion (Université Aix Marseille), auteur de « L’Homme diminué par l’IA », Hermann, 2023-       Laurence Devillers, professeure en IA à Sorbonne Université / CNRS, membre du Comité National Pilote d’Éthique du Numérique, Présidente de la fondation Blaise Pascal en mathématiques et informatique-       Diego Hidalgo, entrepreneur, diplomate, auteur de « Anesthésiés – l’humanité sous l’emprise de la technologie » éditions FYP, 2022. Modérateur : Anthony Laurent, rédacteur en chef de Sciences Critiques.Prise de notes : Victor Fersing, animateur Lève les yeux et créateur de La Fabrique Sociale. </p>  <p>   <br>Anthony Laurent se présente en tant que rédacteur en chef de Sciences Critiques, un média participatif traitant des questions liées à la science, la recherche et aux développements technologiques qui posent de nombreux problèmes politiques. Il introduit les échanges en rappelant que l’IA est un système qui existe et qui se fait de plus en plus présent, invasif, intrusif, dans beaucoup d’aspects de nos vies : le travail, les loisirs, les interactions sociales, l’éducation, la sécurité. Or, nous sommes encore loin d’en comprendre les tenants et les aboutissants et d’en saisir toutes les conséquences, notamment sociales et anthropologique. La numérisation et désormais l’algorithmisation de nos existences personnelles comme collectives modifient en profondeur nos façons de penser, de prendre des décisions, nos façons d’être aux autres, au monde et vis-à-vis de nous-mêmes. La question qui se pose est donc est la suivante : y a-t-il un prix à payer au déploiement de ces technologies ? Et plus précisément, le développement de l’IA est-il inévitable, peut-on la contrôler, peut-on et doit-on y résister, et si oui, comment ?</p>  <p>   <br>Anthony Laurent interroge Laurence Devillers sur la potentielle sacralisation de l’IA, et sur le rôle de l’éthique face à ces enjeux. Laurence Devillers commence par une démystification de ce qu’est l’IA, qui n’est selon elle pas une chose en soi mais un outil, des algorithmes, que l’on peut utiliser de différentes façons pour faire différentes choses, et sur lesquels elle travaille depuis plus de trente ans. Elle rappelle que tout a commencé en 1943 lorsque deux neurobiologistes américains décident de modéliser une cellule du cerveau, puis des réseaux de neurones. En 1986, un algorithme apprend pour la première fois à une machine à partir d’un ensemble de données : quand on parle d’intelligence artificielle aujourd’hui, c’est bien de de cela que l’on parle. Les algorithmes apprennent des fonctions qu’on ne saurait coder, même en étant informaticien. Par exemple, reconnaître la différence entre un chat et un chien à partir de photos. La machine n’a rien d’humain, mais elle regarde avec une acuité qui peut être complémentaire de la nôtre. Quand nous voyons des tables, des chaises, des objets familiers, la machine voit des pixels et regarde parmi toutes les images, les pixels qui se ressemblent, c’est son niveau de compréhension. Pour le cancer, elle peut détecter des signaux que l’on ne voit pas en tant qu’humain. Cependant, un bon médecin expérimenté ne doit pas trop croire la machine et savoir repérer les « faux positifs ». Ces objets peuvent donc être utiles, pour la science, pour la médecine, pour l’écologie, à condition de bien les comprendre. C’est pourquoi pour Laurence Devillers, parler d’éthique, c’est avant tout savoir raisonner sur ces machines, c’est-à-dire savoir dire comment on les fait, quels concepts sont derrière elles, quelle est l’équation exacte entre l’utilité que cela peut avoir, la dépense d’énergie, et les conséquences sociétales. Selon elle, une première chose fascinante est le manque d’éducation sur ces objets. Il est nécessaire que la majorité de la population, au moins les enfants à l’école, soient éduqués pour comprendre comment marche la machine et ainsi éviter de tomber dans le piège de la diabolisation ou de l’attente de quelque chose de « magique ». Cela n’a rien de magique, car il s’agit de statistiques. Certes, on ne comprend pas tout ce qui est codé dans la machine, mais on peut très bien comprendre comment on le fait. Il faut apprendre à les utiliser et à les comprendre. Cependant, il ne faut pas leur prêter des qualités qu’elles n’ont pas, et il ne faut pas craindre de regarder aujourd’hui ce que sont capables de faire ces systèmes. Une anthropologisation est à l’œuvre : on projette sur elles à la fois des connaissances, des affects et des qualités morales. Or elles n’ont pas de connaissances en soi, elles ne font que mouliner automatiquement des données. A propos des affects, la machine est numérique, elle n’a aucune présence et donc aucun affect. On lui prête également des qualités morales, or la machine ne dit ni vérité ni mensonge, elle propose une réponse de façon aléatoire parmi n réponses possibles, et ce avec une base de données spécifique. Il faut donc revenir à la réalité qu’il y a dans ces systèmes : ces outils peuvent nous apporter, en allant chercher des signaux faibles, des signaux qu’on ne voit pas, pour comprendre des situations, synthétiser ou détecter des traits communs. L’éthique, c’est avant tout des outils de compréhension, pour mieux se poser les questions et essayer de comprendre s’il y a vraiment danger ou non, et il faut réglementer cela grâce à un niveau suffisant de connaissance du système. Laurence Devillers précise qu’elle ne cherche pas à dire que cela est merveilleux, mais que l’on a besoin de monter au niveau et on a besoin, dans toute la communauté, d’aller plus loin dans la compréhension de ces objets. Ils peuvent être utiles : par exemple, ils peuvent nous permettre de synthétiser l’information dans une société où l’infobésité nous pose de nombreux problèmes, ou bien ils peuvent nous permettre de détecter les émotions des individus et les aider à se sentir moins seuls. Elle cite les mots de Blaise Pascal : Il faut agir avec raison dans l’incertain. Devant les machines, même si elles parlent désormais notre langage, il faut de plus en plus prendre de la distance. Il faut réguler. On va avoir de plus en plus de mal à distinguer ce qui vient de l’humain ou de la machine, c’est pourquoi il faut cadrer ces différences. Par ailleurs, le pouvoir conféré par des technologies aussi puissantes que ChatGPT à un petit groupe d’individus est dangereux : par exemple, ces machines peuvent devenir le reflet d’une certaine censure. C’est pourquoi il faut pousser les industriels à être plus transparents. Enfin, les enfants ne doivent pas les utiliser comme une prothèse pour écrire car cela va les amener à désapprendre. Ils doivent d’abord apprendre à avoir un raisonnement logique, chose que la machine ne sait pas faire. L’intelligence sera réduite si on fait trop confiance à ces machines, mais il faut apprendre à les utiliser et vérifier par soi-même. Cela peut nous libérer du temps de cerveau pour être plus disponible pour des réalités qui ont vraiment du sens. Ainsi, Laurence Devillers conclut en définissant l’éthique comme la réflexion collective que l’on doit mener autour des risques, en poussant aussi vers les innovations et en comprenant bien les deux aspects.</p>  <p>DR - Vincent Gambardella <br>   <br>Anthony Laurent interroge ensuite Diego Hidalgo sur l’IA en tant qu’elle accentue les tendances de fond qui sont technosolutionnistes : quelle place reste-t-il alors pour l’humain ? Diego Hidalgo introduit sa prise en parole en rappelant qu’il n’est pas un technophobe, qu’il a lui-même lancé des entreprises qui ont fait usage du numérique pour apporter des services et que celui lui semble intéressant. Néanmoins, sa prise de parole sera consacrée à des aspect qui lui semblent vraiment critiques dans les tendances qui dominent en ce moment l’industrie numérique. Il revient dans un premier temps sur deux oppositions à partir desquelles, selon lui, le débat se structure souvent quand on parle des risques de l’IA : la première a trait aux risques de long terme, c’est-à-dire ceux qui prédisent que l’IA va en finir avec le monde, par rapport à d’autres qui dénoncent des risques à court terme notamment aux Etats-Unis sur la question des discriminations ou des biais. Cette opposition est exagérée et n’est pas forcément opératoire ; on peut la transcender car la perte de contrôle de l’humain vis-à-vis de l’autonomie de la machine mérite d’être étudiée sous ces deux formes, en considérant plutôt un spectre de risques qu’une véritable opposition. Le deuxième point oppose ceux qui croiraient en une IA forte, une super IA qui nous concurrencerait avec une puissance de calcul décuplée, et ceux qui pensent qu’on aura toujours une IA faible ou en tous cas qui démystifient ce qu’est l’IA aujourd’hui. Encore une fois, c’est une opposition que l’on peut transcender car dans tous les cas les IA finissent par imposer ou prendre des décisions à notre place.Les deux points qui seront développés sont les suivants :1)     Le fait qu’avec le développement de l’IA on vit une intensification de l’idéologie solutionniste2)     L’optimisation de nos vies qui est impulsée par l’IA et ce que ça signifie pour l’humain Diego Hidalgo revient dans un premier temps sur l’idée de « solutionnisme » : idée selon laquelle la technologie numérique aurait des réponses à toutes nos questions. Selon lui, l’IA risque non seulement de renforcer cette idéologie mais tend également à rendre la technologie plus totalisante.Cela rejoint l’idée selon laquelle la technologie est omnipotente, qu’elle a des réponses à toutes nos questions, non seulement nos questions pratiques et problèmes techniques, mais aussi nos problèmes personnels, professionnels, économiques, sociaux environnementaux même parfois moraux. Si on fait un retour sur les 15-20 dernières années, on remarquera que s’est produit une externalisation assez large de nos fonctions cognitives, et à mesure qu’on a externalisé certaines fonctions, on est devenus de plus en plus dépendant de ces machines. Par exemple, la mémoire ou le sens de l’orientation sont des capacités que l’on perd. En neurologie il y a ce principe de « use it or lose it » : si on n’utilise pas certaines fonctions, elles disparaissent. C’est ce qui fait qu’on ait de plus en plus de mal à lire, ou que les jeunes radiologues, qui s’appuient sur des logiciels d’interprétation d’images, arrivent de moins en moins à lire certaines images d’eux-mêmes car ils font trop confiance à la machine. Un ami de Steve Jobs, Douglas Tomkins, accusait ce dernier d’avoir créé des « deskilling devices », c’est-à-dire des « dispositifs de déqualification ». On voit aussi comment le Flynn, cet effet qui promulguait que décennies après décennies, le quotient intellectuel tendait à augmenter, ne se vérifie plus dernièrement. Pour revenir aux IA génératives, Diego Hidalgo considère qu’elles constituent une externalisation de la pensée, et même si on les démystifie, cette illusion qu’elles ont une réponse à toutes nos questions témoigne d’une externalisation beaucoup plus transversale. Ce n’est plus juste des numéros de téléphone que l’on ne connaît plus ou le GPS qui nous oriente, c’est une réponse beaucoup plus complète à n’importe quel type de question ; ce qui rappelle une citation du philosophe des sciences George Bason qui disait « Et si le prix à payer pour des machines qui pensent, était le fait que les personnes arrêtent de penser ? ». Le fait est qu’on arrête de plus en plus de penser, quand on sait qu’une machine pourra penser pour nous et répondre à toutes nos questions. A propos de l’idée d’une idéologie de plus en plus totalisante, Diego Hidalgo précise que selon lui, on n’externalise pas seulement des fonctions cognitives ou une façon de penser, mais on externalise de plus en plus également nos choix, et des questions de plus en plus larges. L’industrie technologique (ou une partie) a la prétention de nous apporter des solutions qui couvrent des portions de vie de plus en plus larges. Il illustre cette idée avec une campagne menée par Google il y a peut-être 2 ou 3 ans dans le métro de Paris où l’on voyait le moteur de recherche de Google avec des questions qui étaient posées, comme « Que faire avec ses enfants à Paris ? », « Comment vivre mieux ? » ou « Comment changer de vie ? », « Comment être un super-papa ? » : on peut s’interroger sur l’intention de Google avec cette campagne, qui semble être de nous inviter à poser des questions de plus en plus ouvertes, et de ne plus réfléchir par nous-mêmes à ce qu’on va faire avec ses enfants à Paris. Le risque avec ces questions de plus en plus ouvertes, c’est que ces algorithmes dictent leurs décisions dans des aspects de plus en plus ouverts de nos vies : ce qu’on voit, ce qu’on lit, ce qu’on consomme et même avec qui on se marie. L’autre versant de cela, c’est que certaines plateformes ont de plus en plus vocation à répondre à des questions qu’on ne leur a pas posées ! Pour continuer avec Google (même si Google n’a pas le monopole des problèmes mentionnés), cette déclaration d’Éric Schmidt, ancien PDG de Google, a le mérite d’être claire : « Les gens n’attendent pas que Google réponde à leurs questions, mais qu’il leur dicte la prochaine chose qu’ils doivent faire ». Cela donne une bonne idée de la vision de la liberté dans une partie de la Silicon Valley, et ces algorithmes peuvent bien sûr dicter leur décision en fonction de critères qui peuvent nous échapper, dont les intérêts sont souvent commerciaux. Diego Hidalgo aborde ensuite son deuxième point, qui a trait à la recherche d’efficience impulsée par l’IA et la potentielle menace que cette recherche d’efficience, poussée à son paroxysme, pourrait constituer pour l’humain. En d’autres mots : sommes-nous condamnés à disparaître si nous donnons notre confiance à des machines qui sont censées tout faire mieux que nous ?  Une partie de l’industrie technologique tente de nous persuader que nous ne sommes plus si utiles que ça. On peut d’ailleurs souvent voir ce genre de titres dans la presse : est-ce que l’IA va nous remplacer dans tous les métiers ? Une question qui mériterait d’être élargie à bien d’autres facettes de nos vies, même personnelles. Par exemple, si on me promet qu’une IA va éduquer mes enfants mieux que moi, est-ce que je dois mettre au deuxième plan l’amour de mes enfants ? Ou est-ce que je dois refuser ce paradigme ? Les humains sont des êtres imparfaits, et dans cette recherche d’efficience et d’optimisation, on finit par limer ces imperfections, et donc à terme à éliminer l’humain. Dans tout un tas de secteurs, des interactions humains-humains se transforment en interaction humain – machine, puis par des interactions machine – machine. On a parlé dans un autre échange de My AI (chatchot de l’application Snapchat) : jusqu’à il y a un an les adolescents échangeaient au moins avec d’autres adolescents sur Snapchat, aujourd’hui une partie d’entre eux communique avec la machine directement. Diego Hidalgo illustre son propos par un exemple trivial mais qui lui semble important : celui des souhaits d’anniversaire. En tant qu’humains, nous sommes les seuls êtres vivants à se souhaiter nos anniversaires, et on le fait de manière imparfaite à l’image de notre humanité : on peut se tromper de jour, offrir un cadeau qui ne plait pas à la personne… Face à cela, les plateformes ont commencé par nous rappeler les dates d’anniversaires systématiquement donc on se trompe plus, puis elles ont fait en sorte que ce soit de plus en plus facile de souhaiter un joyeux anniversaire en un clic, donc que ça ne demande plus d’effort, et on finit par souhaiter un joyeux anniversaire à tout un tas de personnes qu’on ne connaît pas ou dont on ne se souvient plus, et à en recevoir de personnes qui ne se souviennent plus de nous non plus. Ces souhaits d’anniversaire « parfaits » font l’économie d’une chose mais pas des moindres : l’intention, l’intentionnalité qui permet de leur donner du sens. En conclusion, il cite le philosophe espagnol Ortag y Gasset : « La vie est un processus constant de prises des décisions, il dépend de nous de suivre un chemin ou un autre » Une vie dans laquelle on renonce à prendre ces décisions, même les plus triviales, n’est-elle pas une vie appauvrie ? Quand on pense aux choses qui produisent une grande satisfaction, ce sont rarement des choses automatiques, mais ce sont des choses qui demandent d’être cultivées, qui demandent du temps et des efforts.</p>  <p>DR - Vincent Gambardella <br>   <br>Anthony Laurent s’adresse ensuite à Marius Bertolucci avec une question reprenant les termes de son ouvrage : en quoi l’homme est-il diminué par l’IA ?Marius Bertolucci entame sa prise de parole en citant la célèbre phrase tirée de la Bible : « Je ne suis pas venu apporter la paix mais le glaive ». Il avoue avoir peur, mais d’une peur qui le pousse à agir, à lutter. Il y a 4 ans, il décide d’écrire un livre pour penser le monde, et de s’intéresser à la post modernité, à notre époque qui est celle de la fin des grands récits. En commençant son travail, il s’aperçoit de l’importance que prennent déjà les questions liées à l’intelligence artificielle, et comprend qu’il s’agit désormais du fait social total de notre époque, le secrétaire général de l’ONU estimant même que l’IA est une menace plus grande encore pour l’humanité que le réchauffement climatique. Postmodernité et IA sont ainsi indissociablement liées, car la fin des grands récits (christianisme, nazisme, communisme, libéralisme …) est un terreau fertile, ou plutôt un « désert du réel » sur lequel la machine peut croître.Nous sommes tous effarés face à la puissance technicienne, mais il faut commencer par se demander au nom de quoi nous nous battons. Qu’avons-nous encore à opposer à la machine ? Selon la 3ème loi de Clark : « Toute technologie assez avancée est indiscernable de la magie ». C’est aujourd’hui, selon lui, le cas de l’IA.Marius Bartolucci continue en citant André Malraux : « La nature d’une civilisation, c’est ce qui s’agrège autour d’une religion. Notre civilisation est incapable de construire un temple ou un tombeau. Elle sera contrainte de trouver sa valeur fondamentale, ou elle se décomposera ». Selon lui, nous y sommes. Si une civilisation se construit par la lecture, il est crucial de lire le dernier de Michel Desmurget « Faites-les lire ! Pour en finir avec le crétin digital » (Seuil, 2023) dans lequel on apprend notamment que 3% des petits français sont des grands lecteurs, contre 43% des chinois. Quand on demande à un colonel de l’armée chinoise pourquoi l’algorithme de TikTok présente des vidéos de divertissement mais surtout des vidéos d’art, de science et de glorification patriotique, il répond : « nous protégeons l’avenir de la nation ». Tout est dit. Dans Qu’est-ce que les Lumières ? Emmanuel Kant écrivait : « L’état de tutelle est l’incapacité de se servir de son entendement sans la conduite d’un autre ». Désormais, cet autre est le smartphone, les algorithmes, l’IA. L’enjeu est bien civilisationnel. En quoi l’homme est-il donc diminué ? Une étude est particulièrement frappante selon lui : celle de Jean Twenge, une psychologue qui s’intéresse aux différentes générations aux Etats-Unis depuis les baby-boomers jusqu’aux Gen Z et à leurs différences. La dernière génération a un taux de dépression et de suicide explosif, une proposition démesurée d’adolescents qui ne voient plus leurs amis tous les jours par rapport à la génération précédente, et quand ils se voient leurs écrans sont greffés à leurs mains, et quand ils se parlent de quoi parlent-ils ? Les algorithmes ont décidé pour eux. Si les baby-boomers étaient 85 % à 17 ans à connaître une relation amoureuse, cette génération ne rencontre ses premiers émois qu’à hauteur de 56 %. De la solitude ? Mais rassurez-vous l'application Replika téléchargée 7 millions de fois en Occident et sa version chinoise 660 millions de fois offre l'ami ou le petit ami parfait, et ce, pour tous les âges. Des millions de personnes connaissent une relation amoureuse de ce type aujourd’hui. Marius Bertolucci appelle cet être diminué non pas un cyborg, contraction de cybernetic organism, être augmenté au moyen de la technique (hérité de l’imaginaire de la conquête spatiale des années 60), mais de cybcog, contraction de cybernetic cognition, être dont l’exposition constante aux algorithmes a diminué sa psyché (capacité d’attention, volonté d’apprendre, compétences cognitives…). Pour supporter le capitalisme de surveillance et sa cadence de production, fondée sur l’exploitation de nos données personnelles, le regretté Stakhanov a laissé la place au léthargique Oblomoff qui encaisse 6 à 10h d’écran et déverrouille son smartphone des milliers de fois par jour. L’algorithme est partout et devient éducateur. Le stade du miroir chez Lacan peut désormais être appelé « stade du smartphone ». Désormais, les jeunes ne veulent plus ressembler à des célébrités, mais à leur propre image modifiée par les filtres Snapchat : c’est ce qu’on appelle la « dysmorphie snapchat », qui est évoquée par de nombreux cabinets de chirurgie esthétique aux Etats-Unis. C’est pourquoi on peut oser réactualiser Marx : ce n’est pas la conscience des hommes qui détermine leur existence, c’est au contraire leur existence algorithmique (et non plus sociale) qui détermine leur conscience. La conséquence de tout cela est que nous ne sommes plus des individus, mais comme Deleuze le disait, des « dividuels ». L’algorithme ne s’adresse pas à nous comme des sujets, des êtres de raison. Comme le dit la philosophe Antoinette Rouvroy : « Une propension, un risque, une potentialité, ce n‘est pas encore une personne ». L’individu n’existe plus et avec lui c’est la perte de notre édifice métaphysique et normatif. Certains diront que les politiques sauront nous protéger ; mais l’AI Act que l’Europe vient de voter et qui sera mis en place en 2025, a pour seule ambition de nous protéger du système de contrôle social tel qu’il existe en Chine, une ambition pour ainsi dire plutôt basse. Il y a quelques mois encore le ministre délégué au numérique évoquait de vives réflexions pour empêcher les mineurs d’accéder à la pornographie en ligne. La moitié des garçons de 12 ans et un tiers des filles du même âge sont confrontés à des contenus pornographiques tous les mois. Sur un sujet aussi facile à comprendre et qui provoque l'unanimité, le politique discute encore et ne fait rien. Ce serait ainsi trop leur en demander que de comprendre l'impact néfaste des algorithmes et des écrans sur la motivation, l’attention, l'esprit des plus jeunes, pourtant désormais validé par des milliers d'études académiques à travers le monde. Par ailleurs, au sujet des algorithmes dans le secteur public : aux Pays-Bas, un algorithme mis en place pour la distribution des allocations familiales de 2013 à 2018 a entrainé l’endettement de 26 000 familles et a fait preuve de profilage ethnique, retirant un millier d’enfants à leurs familles. En France, l’ONG Disclose a montré que la Police nationale française utilisait des outils de surveillance algorithmique illégalement. Lorsque que l’on est assisté par une IA, il y a deux solutions : soit on est moins consciencieux dans la décision ; soit parce que l’IA est biaisée on reproduit le biais de la décision. Pour terminer, Marius Bertolucci évoque la question de l’École, que beaucoup souhaitent préserver comme un sanctuaire. Depuis le 1er février 2024, 200 000 élèves de seconde ont le « privilège » de se voir faire enseigner le français et les mathématiques par un système algorithmique. En septembre, tous les élèves de seconde seront concernés. Pourtant, des milliers d’études d'académiques montrent les effets néfastes des écrans sur l'apprentissage ; les écoles de l'Idaho et de la Floride, et même celles de tout un pays comme la Suède on fait marche arrière en matière d'algorithmiques et d’écrans à la vue du désastre en cours ; les élites de l'algorithme, cette « noblesse algorithmique », place ses enfants dans les écoles sans écran. Sans parler du coût financier et écologique de tout ce matériel. Comment ne pas vouloir faire œuvre d’une sainte colère pour protéger les plus jeunes ? Il nous faut désormais agir par le verbe et les actes sans quoi nous serons coupables. Je ne suis pas venu apporter la paix mais le glaive.</p>  <p>DR - Vincent Gambardella </p>

breadcrumbs:
  - title: >-
      Accueil
    path: "/"
  - title: >-
      Actualités
    path: "/actualites/"
  - title: >-
      Intelligence Artificielle : la techno-solution de trop ? - Compte-rendu de la 4ème table ronde des Assises de l'attention 2024

design:
  full_width: false
  toc:
    present: false
    offcanvas: false

authors:
  - "fanny-lepage"
translationKey: communication-website-post-6dd047b4-3723-421c-85ed-f174035b7af0

image:
  id: "600d552f-b5d6-414e-97cb-b5e99a4ca817"
  alt: ""
  credit: >-
    <p>DR - Vincent Gambardella</p>


meta_description: >-
  

summary: >-
  <p>En présence de Marius Bertolucci, Laurence Devillers et Diego Hidalgo. Modération par Anthony Laurent, prise de notes par Victor Fersing. </p>

header_cta:
  display: false
  label: >-
    
  target: ""
  external: false
posts_categories:
  - "a-la-une"
  - "debats"
taxonomies:
  - name: >-
      Catégories
    slug: ""
    path: ""
    categories:
      - permalink: "/actualites/a-la-une/"
        path: "/posts_categories/a-la-une"
        slug: "a-la-une"
        file: "content/fr/posts_categories/a-la-une/_index.html"
        name: >-
          A la Une
      - permalink: "/actualites/debats/"
        path: "/posts_categories/debats"
        slug: "debats"
        file: "content/fr/posts_categories/debats/_index.html"
        name: >-
          Débats, analyses


contents_reading_time:
  seconds: 1132
  text: >-
    19 minutes
contents:
  - kind: block
    template: chapter
    title: >-
      
    slug: >-
      
    ranks:
      base: 2
    top:
      active: false
    data:
      layout: alt_background
      text: >-
        <p>Dérèglement climatique, migrations, gestion administrative, justice, santé… face aux multiples défis auxquels l’humanité fait face, la nouvelle solution des techno prophètes est bien l’intelligence artificielle. Les risques liés à la massification de cette technologie sont, pourtant, étourdissants. Quelles pistes de solutions crédibles sont envisagées, du côté de la société civile ou de l’Union européenne ?</p><p> </p><p>En présence de :</p><p>-       <b>Marius Bertolucci</b>, Maître de conférence en sciences de gestion (Université Aix Marseille), auteur de « L’Homme diminué par l’IA », Hermann, 2023</p><p>-       <b>Laurence Devillers</b>, professeure en IA à Sorbonne Université / CNRS, membre du Comité National Pilote d’Éthique du Numérique, Présidente de la fondation Blaise Pascal en mathématiques et informatique</p><p>-       <b>Diego Hidalgo</b>, entrepreneur, diplomate, auteur de « Anesthésiés – l’humanité sous l’emprise de la technologie » éditions FYP, 2022.</p><p> </p><p>Modérateur : <b>Anthony Laurent</b>, rédacteur en chef de Sciences Critiques.</p><p>Prise de notes : <b>Victor Fersing</b>, animateur Lève les yeux et créateur de <a href="https://www.youtube.com/channel/UCJfgnn1fhvp0GH-e-FVepcg" target="_blank" rel="noreferrer">La Fabrique Sociale. <span class="sr-only">(lien externe)</span></a> </p>

      notes: >-
        


      alt: >-
        

      credit: >-
        



  - kind: block
    template: chapter
    title: >-
      
    slug: >-
      
    ranks:
      base: 2
    top:
      active: false
    data:
      layout: no_background
      text: >-
        <p><b>Anthony Laurent</b> se présente en tant que rédacteur en chef de Sciences Critiques, un média participatif traitant des questions liées à la science, la recherche et aux développements technologiques qui posent de nombreux problèmes politiques.</p><p> </p><p>Il introduit les échanges en rappelant que l’IA est un système qui existe et qui se fait de plus en plus présent, invasif, intrusif, dans beaucoup d’aspects de nos vies : le travail, les loisirs, les interactions sociales, l’éducation, la sécurité. Or, nous sommes encore loin d’en comprendre les tenants et les aboutissants et d’en saisir toutes les conséquences, notamment sociales et anthropologique. La numérisation et désormais l’algorithmisation de nos existences personnelles comme collectives modifient en profondeur nos façons de penser, de prendre des décisions, nos façons d’être aux autres, au monde et vis-à-vis de nous-mêmes. La question qui se pose est donc est la suivante : y a-t-il un prix à payer au déploiement de ces technologies ? Et plus précisément, le développement de l’IA est-il inévitable, peut-on la contrôler, peut-on et doit-on y résister, et si oui, comment ?</p>

      notes: >-
        


      alt: >-
        

      credit: >-
        



  - kind: block
    template: chapter
    title: >-
      
    slug: >-
      
    ranks:
      base: 2
    top:
      active: false
    data:
      layout: no_background
      text: >-
        <p>Anthony Laurent interroge Laurence Devillers sur la potentielle sacralisation de l’IA, et sur le rôle de l’éthique face à ces enjeux.</p><p> </p><p><b>Laurence Devillers</b> commence par une démystification de ce qu’est l’IA, qui n’est selon elle pas une chose en soi mais un outil, des algorithmes, que l’on peut utiliser de différentes façons pour faire différentes choses, et sur lesquels elle travaille depuis plus de trente ans. Elle rappelle que tout a commencé en 1943 lorsque deux neurobiologistes américains décident de modéliser une cellule du cerveau, puis des réseaux de neurones. En 1986, un algorithme apprend pour la première fois à une machine à partir d’un ensemble de données : quand on parle d’intelligence artificielle aujourd’hui, c’est bien de de cela que l’on parle. Les algorithmes apprennent des fonctions qu’on ne saurait coder, même en étant informaticien. Par exemple, reconnaître la différence entre un chat et un chien à partir de photos. La machine n’a rien d’humain, mais elle regarde avec une acuité qui peut être complémentaire de la nôtre. Quand nous voyons des tables, des chaises, des objets familiers, la machine voit des pixels et regarde parmi toutes les images, les pixels qui se ressemblent, c’est son niveau de compréhension. Pour le cancer, elle peut détecter des signaux que l’on ne voit pas en tant qu’humain. Cependant, un bon médecin expérimenté ne doit pas trop croire la machine et savoir repérer les « faux positifs ». Ces objets peuvent donc être utiles, pour la science, pour la médecine, pour l’écologie, à condition de bien les comprendre.</p><p> </p><p>C’est pourquoi pour Laurence Devillers, parler d’éthique, c’est avant tout savoir raisonner sur ces machines, c’est-à-dire savoir dire comment on les fait, quels concepts sont derrière elles, quelle est l’équation exacte entre l’utilité que cela peut avoir, la dépense d’énergie, et les conséquences sociétales. Selon elle, une première chose fascinante est le manque d’éducation sur ces objets. Il est nécessaire que la majorité de la population, au moins les enfants à l’école, soient éduqués pour comprendre comment marche la machine et ainsi éviter de tomber dans le piège de la diabolisation ou de l’attente de quelque chose de « magique ». Cela n’a rien de magique, car il s’agit de statistiques. Certes, on ne comprend pas tout ce qui est codé dans la machine, mais on peut très bien comprendre comment on le fait. Il faut apprendre à les utiliser et à les comprendre.</p><p> </p><p>Cependant, il ne faut pas leur prêter des qualités qu’elles n’ont pas, et il ne faut pas craindre de regarder aujourd’hui ce que sont capables de faire ces systèmes. Une anthropologisation est à l’œuvre : on projette sur elles à la fois des connaissances, des affects et des qualités morales. Or elles n’ont pas de connaissances en soi, elles ne font que mouliner automatiquement des données. A propos des affects, la machine est numérique, elle n’a aucune présence et donc aucun affect. On lui prête également des qualités morales, or la machine ne dit ni vérité ni mensonge, elle propose une réponse de façon aléatoire parmi <i>n</i> réponses possibles, et ce avec une base de données spécifique.</p><p> </p><p>Il faut donc revenir à la réalité qu’il y a dans ces systèmes : ces outils peuvent nous apporter, en allant chercher des signaux faibles, des signaux qu’on ne voit pas, pour comprendre des situations, synthétiser ou détecter des traits communs. L’éthique, c’est avant tout des outils de compréhension, pour mieux se poser les questions et essayer de comprendre s’il y a vraiment danger ou non, et il faut réglementer cela grâce à un niveau suffisant de connaissance du système.</p><p> </p><p>Laurence Devillers précise qu’elle ne cherche pas à dire que cela est merveilleux, mais que l’on a besoin de monter au niveau et on a besoin, dans toute la communauté, d’aller plus loin dans la compréhension de ces objets. Ils peuvent être utiles : par exemple, ils peuvent nous permettre de synthétiser l’information dans une société où l’infobésité nous pose de nombreux problèmes, ou bien ils peuvent nous permettre de détecter les émotions des individus et les aider à se sentir moins seuls.</p><p> </p><p>Elle cite les mots de Blaise Pascal : <i>Il faut agir avec raison dans l’incertain</i>. Devant les machines, même si elles parlent désormais notre langage, il faut de plus en plus prendre de la distance. Il faut réguler. On va avoir de plus en plus de mal à distinguer ce qui vient de l’humain ou de la machine, c’est pourquoi il faut cadrer ces différences. Par ailleurs, le pouvoir conféré par des technologies aussi puissantes que ChatGPT à un petit groupe d’individus est dangereux : par exemple, ces machines peuvent devenir le reflet d’une certaine censure. C’est pourquoi il faut pousser les industriels à être plus transparents.</p><p> </p><p>Enfin, les enfants ne doivent pas les utiliser comme une prothèse pour écrire car cela va les amener à désapprendre. Ils doivent d’abord apprendre à avoir un raisonnement logique, chose que la machine ne sait pas faire. L’intelligence sera réduite si on fait trop confiance à ces machines, mais il faut apprendre à les utiliser et vérifier par soi-même. Cela peut nous libérer du temps de cerveau pour être plus disponible pour des réalités qui ont vraiment du sens.</p><p> </p><p>Ainsi, Laurence Devillers conclut en définissant l’éthique comme la réflexion collective que l’on doit mener autour des risques, en poussant aussi vers les innovations et en comprenant bien les deux aspects.</p>

      notes: >-
        

      image:
        id: "7d84616a-cf79-46c4-a4ad-4f67cdccf4f9"
        file: "7d84616a-cf79-46c4-a4ad-4f67cdccf4f9"

      alt: >-
        

      credit: >-
        <p>DR - Vincent Gambardella</p>



  - kind: block
    template: chapter
    title: >-
      
    slug: >-
      
    ranks:
      base: 2
    top:
      active: false
    data:
      layout: no_background
      text: >-
        <p>Anthony Laurent interroge ensuite Diego Hidalgo sur l’IA en tant qu’elle accentue les tendances de fond qui sont technosolutionnistes : quelle place reste-t-il alors pour l’humain ?</p><p> </p><p><b>Diego Hidalgo</b> introduit sa prise en parole en rappelant qu’il n’est pas un technophobe, qu’il a lui-même lancé des entreprises qui ont fait usage du numérique pour apporter des services et que celui lui semble intéressant. Néanmoins, sa prise de parole sera consacrée à des aspect qui lui semblent vraiment critiques dans les tendances qui dominent en ce moment l’industrie numérique.</p><p> </p><p>Il revient dans un premier temps sur deux oppositions à partir desquelles, selon lui, le débat se structure souvent quand on parle des risques de l’IA : la première a trait aux risques de long terme, c’est-à-dire ceux qui prédisent que l’IA va en finir avec le monde, par rapport à d’autres qui dénoncent des risques à court terme notamment aux Etats-Unis sur la question des discriminations ou des biais. Cette opposition est exagérée et n’est pas forcément opératoire ; on peut la transcender car la perte de contrôle de l’humain vis-à-vis de l’autonomie de la machine mérite d’être étudiée sous ces deux formes, en considérant plutôt un spectre de risques qu’une véritable opposition. Le deuxième point oppose ceux qui croiraient en une IA forte, une super IA qui nous concurrencerait avec une puissance de calcul décuplée, et ceux qui pensent qu’on aura toujours une IA faible ou en tous cas qui démystifient ce qu’est l’IA aujourd’hui. Encore une fois, c’est une opposition que l’on peut transcender car dans tous les cas les IA finissent par imposer ou prendre des décisions à notre place.</p><p>Les deux points qui seront développés sont les suivants :</p><p>1)     Le fait qu’avec le développement de l’IA on vit une intensification de l’idéologie solutionniste</p><p>2)     L’optimisation de nos vies qui est impulsée par l’IA et ce que ça signifie pour l’humain</p><p> </p><p>Diego Hidalgo revient dans un premier temps sur l’idée de « solutionnisme » : idée selon laquelle la technologie numérique aurait des réponses à toutes nos questions. Selon lui, l’IA risque non seulement de renforcer cette idéologie mais tend également à rendre la technologie plus totalisante.</p><p>Cela rejoint l’idée selon laquelle la technologie est omnipotente, qu’elle a des réponses à toutes nos questions, non seulement nos questions pratiques et problèmes techniques, mais aussi nos problèmes personnels, professionnels, économiques, sociaux environnementaux même parfois moraux. Si on fait un retour sur les 15-20 dernières années, on remarquera que s’est produit une externalisation assez large de nos fonctions cognitives, et à mesure qu’on a externalisé certaines fonctions, on est devenus de plus en plus dépendant de ces machines. Par exemple, la mémoire ou le sens de l’orientation sont des capacités que l’on perd. En neurologie il y a ce principe de « use it or lose it » : si on n’utilise pas certaines fonctions, elles disparaissent. C’est ce qui fait qu’on ait de plus en plus de mal à lire, ou que les jeunes radiologues, qui s’appuient sur des logiciels d’interprétation d’images, arrivent de moins en moins à lire certaines images d’eux-mêmes car ils font trop confiance à la machine. Un ami de Steve Jobs, Douglas Tomkins, accusait ce dernier d’avoir créé des « deskilling devices », c’est-à-dire des « dispositifs de déqualification ». On voit aussi comment le Flynn, cet effet qui promulguait que décennies après décennies, le quotient intellectuel tendait à augmenter, ne se vérifie plus dernièrement.</p><p> </p><p>Pour revenir aux IA génératives, Diego Hidalgo considère qu’elles constituent une externalisation de la pensée, et même si on les démystifie, cette illusion qu’elles ont une réponse à toutes nos questions témoigne d’une externalisation beaucoup plus transversale. Ce n’est plus juste des numéros de téléphone que l’on ne connaît plus ou le GPS qui nous oriente, c’est une réponse beaucoup plus complète à n’importe quel type de question ; ce qui rappelle une citation du philosophe des sciences George Bason qui disait « <i>Et si le prix à payer pour des machines qui pensent, était le fait que les personnes arrêtent de penser ?</i> ». Le fait est qu’on arrête de plus en plus de penser, quand on sait qu’une machine pourra penser pour nous et répondre à toutes nos questions.</p><p> </p><p>A propos de l’idée d’une idéologie de plus en plus totalisante, Diego Hidalgo précise que selon lui, on n’externalise pas seulement des fonctions cognitives ou une façon de penser, mais on externalise de plus en plus également nos choix, et des questions de plus en plus larges. L’industrie technologique (ou une partie) a la prétention de nous apporter des solutions qui couvrent des portions de vie de plus en plus larges. Il illustre cette idée avec une campagne menée par Google il y a peut-être 2 ou 3 ans dans le métro de Paris où l’on voyait le moteur de recherche de Google avec des questions qui étaient posées, comme « Que faire avec ses enfants à Paris ? », « Comment vivre mieux ? » ou « Comment changer de vie ? », « Comment être un super-papa ? » : on peut s’interroger sur l’intention de Google avec cette campagne, qui semble être de nous inviter à poser des questions de plus en plus ouvertes, et de ne plus réfléchir par nous-mêmes à ce qu’on va faire avec ses enfants à Paris. Le risque avec ces questions de plus en plus ouvertes, c’est que ces algorithmes dictent leurs décisions dans des aspects de plus en plus ouverts de nos vies : ce qu’on voit, ce qu’on lit, ce qu’on consomme et même avec qui on se marie. L’autre versant de cela, c’est que certaines plateformes ont de plus en plus vocation à répondre à des questions qu’on ne leur a pas posées ! Pour continuer avec Google (même si Google n’a pas le monopole des problèmes mentionnés), cette déclaration d’Éric Schmidt, ancien PDG de Google, a le mérite d’être claire : « <i>Les gens n’attendent pas que Google réponde à leurs questions, mais qu’il leur dicte la prochaine chose qu’ils doivent faire</i> ». Cela donne une bonne idée de la vision de la liberté dans une partie de la Silicon Valley, et ces algorithmes peuvent bien sûr dicter leur décision en fonction de critères qui peuvent nous échapper, dont les intérêts sont souvent commerciaux.</p><p> </p><p>Diego Hidalgo aborde ensuite son deuxième point, qui a trait à la recherche d’efficience impulsée par l’IA et la potentielle menace que cette recherche d’efficience, poussée à son paroxysme, pourrait constituer pour l’humain. En d’autres mots : sommes-nous condamnés à disparaître si nous donnons notre confiance à des machines qui sont censées tout faire mieux que nous ?  Une partie de l’industrie technologique tente de nous persuader que nous ne sommes plus si utiles que ça. On peut d’ailleurs souvent voir ce genre de titres dans la presse : est-ce que l’IA va nous remplacer dans tous les métiers ? Une question qui mériterait d’être élargie à bien d’autres facettes de nos vies, même personnelles. Par exemple, si on me promet qu’une IA va éduquer mes enfants mieux que moi, est-ce que je dois mettre au deuxième plan l’amour de mes enfants ? Ou est-ce que je dois refuser ce paradigme ?</p><p> </p><p>Les humains sont des êtres imparfaits, et dans cette recherche d’efficience et d’optimisation, on finit par limer ces imperfections, et donc à terme à éliminer l’humain. Dans tout un tas de secteurs, des interactions humains-humains se transforment en interaction humain – machine, puis par des interactions machine – machine. On a parlé dans un autre échange de My AI (<i>chatchot de l’application Snapchat)</i> : jusqu’à il y a un an les adolescents échangeaient au moins avec d’autres adolescents sur Snapchat, aujourd’hui une partie d’entre eux communique avec la machine directement.</p><p> </p><p>Diego Hidalgo illustre son propos par un exemple trivial mais qui lui semble important : celui des souhaits d’anniversaire. En tant qu’humains, nous sommes les seuls êtres vivants à se souhaiter nos anniversaires, et on le fait de manière imparfaite à l’image de notre humanité : on peut se tromper de jour, offrir un cadeau qui ne plait pas à la personne… Face à cela, les plateformes ont commencé par nous rappeler les dates d’anniversaires systématiquement donc on se trompe plus, puis elles ont fait en sorte que ce soit de plus en plus facile de souhaiter un joyeux anniversaire en un clic, donc que ça ne demande plus d’effort, et on finit par souhaiter un joyeux anniversaire à tout un tas de personnes qu’on ne connaît pas ou dont on ne se souvient plus, et à en recevoir de personnes qui ne se souviennent plus de nous non plus. Ces souhaits d’anniversaire « parfaits » font l’économie d’une chose mais pas des moindres : l’intention, l’intentionnalité qui permet de leur donner du sens.</p><p> </p><p>En conclusion, il cite le philosophe espagnol Ortag y Gasset : « <i>La vie est un processus constant de prises des décisions, il dépend de nous de suivre un chemin ou un autre</i> »</p><p> </p><p>Une vie dans laquelle on renonce à prendre ces décisions, même les plus triviales, n’est-elle pas une vie appauvrie ? Quand on pense aux choses qui produisent une grande satisfaction, ce sont rarement des choses automatiques, mais ce sont des choses qui demandent d’être cultivées, qui demandent du temps et des efforts.</p>

      notes: >-
        

      image:
        id: "4babd884-8d6c-48fb-ae46-dfc9e0b45ffc"
        file: "4babd884-8d6c-48fb-ae46-dfc9e0b45ffc"

      alt: >-
        

      credit: >-
        <p>DR - Vincent Gambardella</p>



  - kind: block
    template: chapter
    title: >-
      
    slug: >-
      
    ranks:
      base: 2
    top:
      active: false
    data:
      layout: no_background
      text: >-
        <p>Anthony Laurent s’adresse ensuite à Marius Bertolucci avec une question reprenant les termes de son ouvrage : en quoi l’homme est-il diminué par l’IA ?</p><p><b>Marius Bertolucci</b> entame sa prise de parole en citant la célèbre phrase tirée de la Bible : « <i>Je ne suis pas venu apporter la paix mais le glaive</i> ». Il avoue avoir peur, mais d’une peur qui le pousse à agir, à lutter. Il y a 4 ans, il décide d’écrire un livre pour penser le monde, et de s’intéresser à la post modernité, à notre époque qui est celle de la fin des grands récits. En commençant son travail, il s’aperçoit de l’importance que prennent déjà les questions liées à l’intelligence artificielle, et comprend qu’il s’agit désormais du fait social total de notre époque, le secrétaire général de l’ONU estimant même que l’IA est une menace plus grande encore pour l’humanité que le réchauffement climatique. Postmodernité et IA sont ainsi indissociablement liées, car la fin des grands récits (christianisme, nazisme, communisme, libéralisme …) est un terreau fertile, ou plutôt un « désert du réel » sur lequel la machine peut croître.</p><p>Nous sommes tous effarés face à la puissance technicienne, mais il faut commencer par se demander au nom de quoi nous nous battons. Qu’avons-nous encore à opposer à la machine ? Selon la 3<sup>ème</sup> loi de Clark : « <i>Toute technologie assez avancée est indiscernable de la magie</i> ». C’est aujourd’hui, selon lui, le cas de l’IA.</p><p>Marius Bartolucci continue en citant André Malraux : « <i>La nature d’une civilisation, c’est ce qui s’agrège autour d’une religion. Notre civilisation est incapable de construire un temple ou un tombeau. Elle sera contrainte de trouver sa valeur fondamentale, ou elle se décomposera</i> ». Selon lui, nous y sommes. Si une civilisation se construit par la lecture, il est crucial de lire le dernier de Michel Desmurget « Faites-les lire ! Pour en finir avec le crétin digital » (Seuil, 2023) dans lequel on apprend notamment que 3% des petits français sont des grands lecteurs, contre 43% des chinois. Quand on demande à un colonel de l’armée chinoise pourquoi l’algorithme de TikTok présente des vidéos de divertissement mais surtout des vidéos d’art, de science et de glorification patriotique, il répond : « nous protégeons l’avenir de la nation ». Tout est dit.</p><p> </p><p>Dans <i>Qu’est-ce que les Lumières ?</i> Emmanuel Kant écrivait : « <i>L’état de tutelle est l’incapacité de se servir de son entendement sans la conduite d’un autre</i> ». Désormais, cet autre est le smartphone, les algorithmes, l’IA. L’enjeu est bien civilisationnel.</p><p> </p><p>En quoi l’homme est-il donc diminué ? Une étude est particulièrement frappante selon lui : celle de Jean Twenge, une psychologue qui s’intéresse aux différentes générations aux Etats-Unis depuis les baby-boomers jusqu’aux Gen Z et à leurs différences. La dernière génération a un taux de dépression et de suicide explosif, une proposition démesurée d’adolescents qui ne voient plus leurs amis tous les jours par rapport à la génération précédente, et quand ils se voient leurs écrans sont greffés à leurs mains, et quand ils se parlent de quoi parlent-ils ? Les algorithmes ont décidé pour eux. Si les baby-boomers étaient 85 % à 17 ans à connaître une relation amoureuse, cette génération ne rencontre ses premiers émois qu’à hauteur de 56 %. De la solitude ? Mais rassurez-vous l'application Replika téléchargée 7 millions de fois en Occident et sa version chinoise 660 millions de fois offre l'ami ou le petit ami parfait, et ce, pour tous les âges. Des millions de personnes connaissent une relation amoureuse de ce type aujourd’hui.</p><p> </p><p>Marius Bertolucci appelle cet être diminué non pas un cyborg, contraction de <i>cybernetic organism</i>, être augmenté au moyen de la technique (hérité de l’imaginaire de la conquête spatiale des années 60), mais de cybcog, contraction de <i>cybernetic cognition</i>, être dont l’exposition constante aux algorithmes a diminué sa psyché (capacité d’attention, volonté d’apprendre, compétences cognitives…). Pour supporter le capitalisme de surveillance et sa cadence de production, fondée sur l’exploitation de nos données personnelles, le regretté Stakhanov a laissé la place au léthargique Oblomoff qui encaisse 6 à 10h d’écran et déverrouille son smartphone des milliers de fois par jour.</p><p> </p><p>L’algorithme est partout et devient éducateur. Le stade du miroir chez Lacan peut désormais être appelé « stade du smartphone ». Désormais, les jeunes ne veulent plus ressembler à des célébrités, mais à leur propre image modifiée par les filtres Snapchat : c’est ce qu’on appelle la « dysmorphie snapchat », qui est évoquée par de nombreux cabinets de chirurgie esthétique aux Etats-Unis.</p><p> </p><p>C’est pourquoi on peut oser réactualiser Marx : ce n’est pas la conscience des hommes qui détermine leur existence, c’est au contraire leur existence <i>algorithmique</i> (et non plus sociale) qui détermine leur conscience. La conséquence de tout cela est que nous ne sommes plus des individus, mais comme Deleuze le disait, des « dividuels ». L’algorithme ne s’adresse pas à nous comme des sujets, des êtres de raison. Comme le dit la philosophe Antoinette Rouvroy : « <i>Une propension, un risque, une potentialité, ce n‘est pas encore une personne</i> ». L’individu n’existe plus et avec lui c’est la perte de notre édifice métaphysique et normatif.</p><p> </p><p>Certains diront que les politiques sauront nous protéger ; mais l’AI Act que l’Europe vient de voter et qui sera mis en place en 2025, a pour seule ambition de nous protéger du système de contrôle social tel qu’il existe en Chine, une ambition pour ainsi dire plutôt basse. Il y a quelques mois encore le ministre délégué au numérique évoquait de vives réflexions pour empêcher les mineurs d’accéder à la pornographie en ligne. La moitié des garçons de 12 ans et un tiers des filles du même âge sont confrontés à des contenus pornographiques tous les mois. Sur un sujet aussi facile à comprendre et qui provoque l'unanimité, le politique discute encore et ne fait rien. Ce serait ainsi trop leur en demander que de comprendre l'impact néfaste des algorithmes et des écrans sur la motivation, l’attention, l'esprit des plus jeunes, pourtant désormais validé par des milliers d'études académiques à travers le monde.</p><p> </p><p>Par ailleurs, au sujet des algorithmes dans le secteur public : aux Pays-Bas, un algorithme mis en place pour la distribution des allocations familiales de 2013 à 2018 a entrainé l’endettement de 26 000 familles et a fait preuve de profilage ethnique, retirant un millier d’enfants à leurs familles. En France, l’ONG Disclose a montré que la Police nationale française utilisait des outils de surveillance algorithmique illégalement. Lorsque que l’on est assisté par une IA, il y a deux solutions : soit on est moins consciencieux dans la décision ; soit parce que l’IA est biaisée on reproduit le biais de la décision.</p><p> </p><p>Pour terminer, Marius Bertolucci évoque la question de l’École, que beaucoup souhaitent préserver comme un sanctuaire. Depuis le 1er février 2024, 200 000 élèves de seconde ont le « privilège » de se voir faire enseigner le français et les mathématiques par un système algorithmique. En septembre, tous les élèves de seconde seront concernés. Pourtant, des milliers d’études d'académiques montrent les effets néfastes des écrans sur l'apprentissage ; les écoles de l'Idaho et de la Floride, et même celles de tout un pays comme la Suède on fait marche arrière en matière d'algorithmiques et d’écrans à la vue du désastre en cours ; les élites de l'algorithme, cette « noblesse algorithmique », place ses enfants dans les écoles sans écran. Sans parler du coût financier et écologique de tout ce matériel. Comment ne pas vouloir faire œuvre d’une sainte colère pour protéger les plus jeunes ?</p><p> </p><p>Il nous faut désormais agir par le verbe et les actes sans quoi nous serons coupables. <i>Je ne suis pas venu apporter la paix mais le glaive.</i></p>

      notes: >-
        

      image:
        id: "48313fb0-96ea-41cc-8d63-246a52e05ebb"
        file: "48313fb0-96ea-41cc-8d63-246a52e05ebb"

      alt: >-
        

      credit: >-
        <p>DR - Vincent Gambardella</p>




---
